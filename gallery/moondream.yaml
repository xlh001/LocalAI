---
name: "moondream2"


config_file: |
    backend: llama-cpp
    context_size: 2046
    roles:
      user: "\nQuestion: "
      system: "\nSystem: "
      assistant: "\nAnswer: "
    stopwords:
    - "Question:"
    - "<|endoftext|>"
    f16: true
    template:
      completion: |
        Complete the following sentence: {{.Input}}
      chat: "{{.Input}}\nAnswer:\n"
